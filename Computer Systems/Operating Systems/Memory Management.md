Section: [[Operating Systems (Root)]]

The operating system needs to keep track of free and taken memory, as well as allocate/deallocate it to processes. Basically it decides which processes and data needs to be transferred between RAM and disk

To realise the performance of [[CPU Scheduling#Optimisation Criteria|scheduling optimisation]] we need to be able to keep processes in the same memory
# Memory Types

- Cache memory
	- Primary storage
	- Managed by the CPU
	- Invisible to the OS
- Main memory
	- Primary storage
	- RAM and such
	- Volatile
	- We are focusing on this
- Storage memory
	- Non-volatile
	- Disk and such
- Virtual memory
## Basic Hardware

Each process has its own **memory space**, with a pair of **base** and **limit** registers defining the logical address space.
# Hardware Address Protection

This is when we protect memory to ensure correct operation by separating per-process memory to protect them from each other
![[Pasted image 20250405183916.png]]
## Logical and Physical Addressing

A logic address is generated by the CPU, often referred to as a **virtual address**. A physical address is the address as seen by the memory unit.

The concept of a logical address space that is bound to a separate physical address space is central to proper memory management..
## Memory Management Unit (MMU)

A hardware device that (at run time) maps virtual to physical addresses by adding the value in a **relocation register** to every logical address
![[Pasted image 20250405184500.png]]
## Memory Partitioning

We usually split main memory into one part for the **kernel** and another for the **user** (two contiguous parts). Each partition is stored in a single contiguous section of memory
## Memory Protection

Relocation registers protect processes from each other. The base register contains the value of smallest physical address, the limit register contains the range of logical addresses. This lets us define what addresses a process is taking
![[Pasted image 20250405184856.png]]
## Contiguous Allocation

Contiguous memory can be read in sequence and thus **faster**. To do this we need a **hole** (a block of available memory). Holes vary in size throughout memory, and we want to find one large enough to fit the process we are allocating. There are many strategies for this:

- First-fit
	- Allocate the first hole that is big enough
- Best-fit
	- Allocate the smallest hole that is big enough
	- Need to search the whole list (unless ordered)
	- Produces the smallest leftover hole
- Worse-fit
	- Allocate the largest hole
	- Need to search the entire list
	- Produces the largest leftover hole

Exiting a process frees its partition like so:
![[Pasted image 20250405185520.png]]
## Fragmentation

**External fragmentation** is a **non-contiguous** memory space able to satisfy a request

**Internal fragmentation** is contiguous memory allocated successfully but possibly slightly larger than the requested amount of memory. This is because size of memory stored in blocks is divisible by a given $2^n$ so you often have more than needed 

The **50% Rule** dictates that given $N$ blocks allocated, $\frac N2$ blocks are lost to fragmentation (meaning 1/3 may be unusable). We can fix this using **compaction** (shuffling memory contents to place free memory together in a bigger block)
## Paging

The physical address space of a process can be non-contiguous. This avoids external fragmentation and varying sized memory chunks.

Physical memory is divided into fixed-sized blocks called **frames**, typically in sizes of a power of 2 between 512 and 8192 bytes. Logical memory is divided into blocks of the same size called **pages**

To run a program of size $n$ pages, we need to find $n$ free frames and load the program (**paging**)

A **page table** helps manage mapping logical to physical addresses using address translation, but we still have **internal fragmentation**
## Address Translation Scheme

The logical memory address generated by the CPU contains the **page number** (p), an index into the page table showing the base address of each page, as well as the **page offset** (d), which combines with the base address to define the physical memory address sent to the memory unit
![[Pasted image 20250405191225.png]]
Where there is a logical address space $2^m$ and page size $2^n$
## Paging Hardware

Here is what the MMU does to translate logical addresses to physical addresses

1. Extract the page number and use it as the index in the page table
2. Extract the frame number from the page table
3. Replace the page number in the logical address with the frame number
![[Pasted image 20250405191609.png]]
![[Pasted image 20250405192253.png]]


But what if I want to *implement* my page table?

The page table is kept in main memory with a register pointing to its base. This means that every data/instruction requires a memory location for the page table and as well as one for the data/instruction. This can be fixed by a...
## Translation Look-aside Buffer (TLB)

![[Pasted image 20250304135139.png]]

The MMU first checks if a page number is in the TLB. If one is found, then the frame number is immediately available and used to access memory. Otherwise, a memory reference to the page table is made. This means the frame number is obtained and both page and frame number are added to the TLB. Adding the page and frame number to the TLB ensures a quicker lookup next time

If the TLB is full, we need to replace an existing entry
## Effective Access Time (EAT)

Hit ratio (denoted $\alpha$) is the percentage of times a page number is found in the associative registers

$EAT=(\alpha\times\text{memory access time}) + 2(1-\alpha)(\text{memory access time)}$

This is because when there is a [[Memory Management#Translation Look-aside Buffer (TLB)|TLB]] hit, memory must only be accessed once. Otherwise, memory must be accessed twice. We assume the time taken to read the TLB to be **negligible**
## Protection

A **protection bit** for each frame implements memory protection. A valid indicates the associated page is in the logical address space, whereas an invalid indicates otherwise
![[Pasted image 20250405211102.png]]

## Virtual Memory

An OS capability that allows programs to address more memory locations than main memory *actually* offers

This removes the burden of memory management from programmers

Essentially, the logical address space is larger than the physical address space, and pages are swapped/paged in and out of main memory. You don't need *all* of the process in the physical address space for execution.
## Virtual Address Space

Each process views the address space as a **contiguous** block of memory holding the following:

- Code
- Data
- Heap
	- Address space in memory storing data produced during execution
- Stack
	- Address space holding instructions and data from the time of the procedure call
## Demand Paging

Bringing pages into memory only when needed during execution

This reduces the number of pages transferred as well as the number of frames per process

But it also increases the overall response time for a collection of processes and the number of processes executing
## A Process's Page Table

When a reference is made to a page's address, if the reference is invalid then we abort. If the reference is not-in-memory then we bring it to memory

A valid/invalid bit is associated with each process's page table entry to show if it is already in memory
![[Pasted image 20250405212353.png]]
## Handling Page Fault Traps

- A process requests access to an address in a page:
- Check the validity of the process's access to the page
- If invalid:
	- Terminate process
	- Clear previously allocated main memory
	- Throw and error
- If valid
	- If page is allocated a frame then all is good
	- Otherwise, we have a **page fault trap**:
		- Find a free frame from the free frame list
		- Read the page into the frame
		- Update the process's page table
		- Restart the instruction
![[Pasted image 20250405213623.png]]
## Demand Paging Performance

Define the **Page Fault Rate** as $p,0\leq p\leq 1$. A $p$ of 0 indicates no page fault

Our **Effective Access Time** can be found using the following:

$EAT=(1-p)\text{memory access}+p(\text{page fault overhead}+\text{swap page out}+\text{swap page in})$
The **page fault overhead** includes:

- Context switching when relinquishing the CPU
- Time waiting in the paging device queue
- Time waiting back in the ready queue
- Context switching when regaining the ready queue
## No Free Frames

When all main memory frames available for a process are currently allocated, we need to undergo **page replacement**. We find a page in memory that is not really in use and swap it out. We have some algorithms to do this, with the aim of minimising **page faults**
## Basic Page Replacement

- Find the location of the desired page on the disk
- Find a free frame
	- If there is one then use it
	- If there is none then use a page-replacement algorithm to select a **victim page**
	- Write the victim page to disk and update the process's page table and free frame list
- Read the desired page into the freed frame
	- Update the page table and free frame list
- Restart the user process
# Replacement Algorithms

These are evaluated by how well they perform in terms of minimising the number of page faults
### First in First out (FIFO)

Each page has an associated time it was brought into memory. The victim page is always the **oldest** page. We can implement this as a queue without needing to actually track the ageing time.

Below is a demonstration, we have a reference string of memory frames and three frames:

| String    | 7    | 0    | 1    | 2    | 0    | 3    | 0    | 4    | 2    | 3    | 0    | 3    | 0    | 3    | 2    | 1    | 2    | 0   | 1   | 7    | 0    | 1    |
| --------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | --- | --- | ---- | ---- | ---- |
| Frame 1   | 7    | 7    | 7    | 2    |      | 2    | 2    | 4    | 4    | 4    | 0    |      |      |      |      | 0    | 0    |     |     | 7    | 7    | 7    |
| Frame 2   |      | 0    | 0    | 0    |      | 3    | 3    | 3    | 2    | 2    | 2    |      |      |      |      | 1    | 1    |     |     | 1    | 0    | 0    |
| Frame 3   |      |      | 1    | 1    |      | 1    | 0    | 0    | 0    | 3    | 3    |      |      |      |      | 3    | 2    |     |     | 2    | 2    | 1    |
| Page hit? | miss | miss | miss | miss | hit! | miss | miss | miss | miss | miss | miss | hit! | hit! | hit! | hit! | miss | miss | hit | hit | miss | miss | miss |

We have 15 page faults here
### Belady's Anomaly

For some fault algorithms, increasing the number of allocated frames will actually increase the page fault rate. This is counterintuitive, as usually increasing the size of memory will improve the memory response.
### Optimal Algorithm

In an ideal world, we'd want to replace the page that will not be needed for the longest period of time. But this requires knowing the future, which is impossible without any degree of *clairvoyance* (our current operating systems do not possess this ability)
### Least Recently Used (LRU)

In this algorithm, we associate the time of last use with each page. The victim page will be the page that has not been used for the longest period of time

This is a **stack algorithm**, which can never exhibit [[Memory Management#Belady's Anomaly|Belady's Anomaly]]. A set of pages in memory for $n$ frames is always a subset of the set of pages that would be in memory with $n+1$ frames

We can implement LRU using a **counter**, recording the time every time a page is referenced. Or we can use a **stack**, where when a page is referenced we move it to the top of the stack (altering pointers). In our stack implementation, the tail will be the victim page
# Allocation of Frames

- Global replacement:
	- Select a replacement frame from the set of all frames (a process can take a frame from another)
- Local replacement:
	- Select only from the process's on set of allocated frames
- Fixed allocation:
	- Equal allocation
- Proportional allocation:
	- Allocate according to size of process
- Priority allocation:
	- Select a replacement from a process with a lower priority number
## Thrashing

This refers to when a process is spending more time paging than doing actual work. This often occurs when a process does not have enough pages. Thrashing can lead to low CPU utilisation, as the OS will think that it needs to increase the degree of multiprogramming and will add more processes.

We can fix this with...
## Prepaging

Page into memory ,at one time, all the pages that will be needed
![[Pasted image 20250405221546.png]]
We keep with a process a list of pages in its working set model. When a process is suspended we remember the working set so we can bring the whole set into memory when the process resumes. This prevents thrashing so long as the cost of prepaging is less than the cost of servicing page faults

We can also fix thrashing with a...
## Page-Fault Frequency Scheme

We establish an acceptable page-fault rate. If the actual rate is too low then the process has too many frames, otherwise the process has too many frames. The number of frames is then adjusted accordingly